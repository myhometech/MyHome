Here‚Äôs a clear, structured instruction set for your Dev GPT to implement and test a fix for PostgreSQL connection reliability issues, including automatic reconnection and resilience patterns:

‚∏ª

üõ†Ô∏è Instructions for Dev GPT: PostgreSQL Connection Reliability Fix

üî¥ Issue Summary
	‚Ä¢	Symptom: PostgreSQL connection error ‚Äî ‚Äúterminating connection due to administrator command‚Äù
	‚Ä¢	Impact: Full system outage when DB connection drops
	‚Ä¢	Goal: Add resiliency so app stays functional during brief outages or reconnections

‚∏ª

‚úÖ Implementation Tasks

1. Introduce Connection Pooling
	‚Ä¢	Tool: Use a library like pg-pool (if using Node.js), or ORM-native pooling (e.g., Prisma, Sequelize)
	‚Ä¢	Config:
	‚Ä¢	Set sensible limits: max: 10‚Äì20, idleTimeoutMillis: 30_000, connectionTimeoutMillis: 5_000
	‚Ä¢	Example (for pg-pool):

const pool = new Pool({
  max: 20,
  connectionTimeoutMillis: 5000,
  idleTimeoutMillis: 30000,
});


	‚Ä¢	Outcome: Prevents overloading and supports reuse of connections

‚∏ª

2. Add Automatic Reconnection Logic
	‚Ä¢	Wrap query logic in a retry mechanism for transient errors:
	‚Ä¢	Use backoff strategy (e.g., retry up to 3 times with 1s, 2s, 4s delay)
	‚Ä¢	Only retry for known transient errors (e.g., ECONNRESET, Connection terminated unexpectedly)

async function retryQuery(queryFn, attempts = 3) {
  for (let i = 0; i < attempts; i++) {
    try {
      return await queryFn();
    } catch (err) {
      if (i === attempts - 1 || !isTransientError(err)) throw err;
      await wait(1000 * 2 ** i); // backoff
    }
  }
}


‚∏ª

3. Implement Circuit Breaker Pattern
	‚Ä¢	Use a library like opossum (Node.js) or build your own:
	‚Ä¢	Trip circuit after 3 failed DB attempts in a 30s window
	‚Ä¢	Automatically retry after a cooldown period (e.g., 10s)
	‚Ä¢	While open, serve fallback responses or ‚ÄúService temporarily unavailable‚Äù

const breaker = new CircuitBreaker(dbQueryFunction, {
  timeout: 5000,
  errorThresholdPercentage: 50,
  resetTimeout: 10000,
});


‚∏ª

4. Graceful Error Handling in API Layer
	‚Ä¢	Wrap DB calls with error boundaries that return user-friendly errors
	‚Ä¢	Avoid full crashes due to uncaught database failures
	‚Ä¢	Show maintenance banner if circuit is open or DB is unreachable

‚∏ª

‚úÖ Testing Plan

1. Unit Tests
	‚Ä¢	Simulate transient DB failures and assert retries work
	‚Ä¢	Verify fallback response when circuit is open

2. Integration Tests
	‚Ä¢	Manually stop the DB and restart
	‚Ä¢	Confirm:
	‚Ä¢	API retries during disconnection window
	‚Ä¢	Circuit opens after repeated failures
	‚Ä¢	Circuit resets after cooldown
	‚Ä¢	App recovers without needing restart

3. Load Test
	‚Ä¢	Simulate 100 concurrent users during a DB outage
	‚Ä¢	Ensure:
	‚Ä¢	App doesn‚Äôt crash
	‚Ä¢	Pool limits are respected
	‚Ä¢	Memory/CPU usage stays within acceptable bounds

‚∏ª

Would you like me to write a GitHub issue template or PR checklist based on this implementation?